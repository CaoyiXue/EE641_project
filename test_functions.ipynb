{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seg_models.micronet_backbone import micronet\n",
    "from seg_models.micronet_backbone import cfg\n",
    "import seg_models as sm\n",
    "import torch\n",
    "import utils\n",
    "import torchio as tio\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infect_path = \"data/Infection Segmentation Data Transformed/\"\n",
    "infect_train_loader, infect_val_loader, infect_test_loader = utils.get_loader(\n",
    "    target_directory=infect_path, train_bs=2,\n",
    "    val_bs=2, num_works=2)\n",
    "lung_path = \"data/Lung Segmentation Data Transformed/\"\n",
    "lung_train_loader, lung_val_loader, lung_test_loader = utils.get_loader(\n",
    "    target_directory=lung_path, train_bs=64,\n",
    "    val_bs=64, num_works=2)\n",
    "len(infect_train_loader.dataset), len(lung_train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet(\n",
    "    encoder_name=\"micronet_m0\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "optimizer = optim.Adam(lr=0.001)\n",
    "loss_fnc = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infect_value = next(iter(infect_train_loader))\n",
    "lung_value = next(iter(lung_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infect_value['infection mask'][tio.DATA].shape, lung_value['lung mask'][tio.DATA].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check loss function calculation\n",
    "imgs = lung_value['image'][tio.DATA].squeeze_(-1)\n",
    "labels = lung_value['lung mask'][tio.DATA].squeeze_(1)\n",
    "labels = labels.squeeze_(-1).long()\n",
    "outputs = model(imgs)\n",
    "_, predicted = torch.max(outputs, dim=1)\n",
    "print(outputs.shape, labels.shape)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "print(loss(outputs, labels).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unet_micronet_m0 = sm.Unet(\n",
    "    encoder_name=\"micronet_m0\",       \n",
    "    in_channels=1,                  \n",
    "    classes=2,                      \n",
    ")\n",
    "optimizer = optim.Adam(Unet_micronet_m0.parameters(), lr=0.001)\n",
    "loss_fcn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.training_loop(Unet_micronet_m0, optimizer, \n",
    "loss_fcn, infect_train_loader, \n",
    "infect_val_loader, mask_name='infection mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test test_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.test_loop(infect_test_loader, model, mask_name='infection mask');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test metric accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "imgs = infect_value['image'][tio.DATA].squeeze_(-1)\n",
    "labels = infect_value['infection mask'][tio.DATA].squeeze_(-1).long()\n",
    "outputs = model(imgs)\n",
    "_, predicted = torch.max(outputs, dim=1)\n",
    "print(predicted.view(-1).shape, labels.view(-1).shape)\n",
    "print(utils.accuracy(predicted, labels), utils.IoU(predicted, labels), utils.DSC(predicted, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calc_Accuracy_Sets(truth, pred, c=1, **kwargs):\n",
    "    # Obtain sets with associated class\n",
    "    gt = np.equal(truth, c)\n",
    "    pd = np.equal(pred, c)\n",
    "    not_gt = np.logical_not(gt)\n",
    "    not_pd = np.logical_not(pd)\n",
    "    # Calculate Accuracy\n",
    "    acc = (np.logical_and(pd, gt).sum() + \\\n",
    "           np.logical_and(not_pd, not_gt).sum()) / gt.size\n",
    "    # Return computed Accuracy\n",
    "    return acc\n",
    "def calc_IoU_Sets(truth, pred, c=1, **kwargs):\n",
    "    # Obtain sets with associated class\n",
    "    gt = np.equal(truth, c)\n",
    "    pd = np.equal(pred, c)\n",
    "    # Calculate IoU\n",
    "    if  (pd.sum() + gt.sum() - np.logical_and(pd, gt).sum()) != 0:\n",
    "        iou = np.logical_and(pd, gt).sum() / \\\n",
    "              (pd.sum() + gt.sum() - np.logical_and(pd, gt).sum())\n",
    "    else : iou = 0.0\n",
    "    # Return computed IoU\n",
    "    return iou\n",
    "def calc_DSC_Sets(truth, pred, c=1, **kwargs):\n",
    "    # Obtain sets with associated class\n",
    "    gt = np.equal(truth, c)\n",
    "    pd = np.equal(pred, c)\n",
    "    # Calculate Dice\n",
    "    if (pd.sum() + gt.sum()) != 0:\n",
    "        dice = 2*np.logical_and(pd, gt).sum() / (pd.sum() + gt.sum())\n",
    "    else : dice = 0.0\n",
    "    # Return computed Dice\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "# Get some ground truth / annotated segmentations\n",
    "truth = np.random.randint(2, size=(64,64))  # binary (2 classes)\n",
    "# Get some predicted segmentations\n",
    "np.random.seed(2)\n",
    "pred = np.random.randint(2, size=(64,64))  # binary (2 classes)\n",
    "\n",
    "print(calc_Accuracy_Sets(truth, pred), utils.accuracy(torch.tensor(pred), torch.tensor(truth)))\n",
    "print(calc_IoU_Sets(truth, pred), utils.IoU(torch.tensor(pred), torch.tensor(truth)))\n",
    "print(calc_DSC_Sets(truth, pred), utils.DSC(torch.tensor(pred), torch.tensor(truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[0,1],[1,0]])\n",
    "b = torch.tensor([[0,1],[0,1]])\n",
    "((a+b)>0).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ee641')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c0369900df99c3522d8011e6f2450545a3abb69754db692ed3545e074f222a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
